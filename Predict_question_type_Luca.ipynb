{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VQA annotations and questions into memory...\n",
      "0:00:07.300260\n",
      "creating index...\n",
      "index created!\n",
      "loading VQA annotations and questions into memory...\n",
      "0:00:08.186969\n",
      "creating index...\n",
      "index created!\n",
      "Question features (496698, 32)\n",
      "Dictionary size 14178\n"
     ]
    }
   ],
   "source": [
    "from PrepareOriginalData import PrepareData\n",
    "import numpy as np\n",
    "\n",
    "# Some constants\n",
    "taskType = 'all'\n",
    "data_amount = 1\n",
    "epochs = 200\n",
    "\n",
    "# Load training set\n",
    "p = PrepareData(path_images='data_vqa_feat', # Path to image features \n",
    "                subset='train2014', # Desired subset: either train2014 or val2014\n",
    "                taskType=taskType, # 'OpenEnded', 'MultipleChoice', 'all'\n",
    "                cut_data=data_amount, # Percentage of data to use, 1 = All values, above 1=#samples for debugging\n",
    "                output_path='data', # Path where we want to output temporary data\n",
    "                pad_length=32, # Number of words in a question (zero padded)\n",
    "                question_threshold=0, answer_threshold=0, # Keep only most common words\n",
    "                answers_sparse=True, questions_sparse=True)\n",
    "_, questions, _, annotations = p.load_data()\n",
    "print(\"Question features\", questions.shape)\n",
    "print(\"Dictionary size\", p.dic_size)\n",
    "\n",
    "# Save dictionary\n",
    "p.dumpDictionary('dictionary_all_types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496698,)\n"
     ]
    }
   ],
   "source": [
    "# Get labels\n",
    "y = np.array([2 if ann['answer_type'] == 'number' else 1 if ann['answer_type'] == 'yes/no' else 0 for ann in annotations])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "word_input (InputLayer)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "word_embedding (Embedding)   (None, 32, 64)            907392    \n",
      "_________________________________________________________________\n",
      "flatten_embedding (Flatten)  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 3,705,219\n",
      "Trainable params: 3,705,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#classifier = RandomForestClassifier()\n",
    "#classifier.fit(questions, y)\n",
    "from NeuralNetworkQuestionType import NeuralNetwork\n",
    "neuralnetQuestionType = NeuralNetwork(questions.shape[1], p.dic_size, 3, epochs=epochs, batchSize=64, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496698, 32) (496698,)\n",
      "Train on 347688 samples, validate on 149010 samples\n",
      "Epoch 1/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9878Epoch 00001: val_acc improved from -inf to 0.99375, saving model to weights/weights-01-0.0224.hdf5\n",
      "347688/347688 [==============================] - 67s 193us/step - loss: 0.0412 - acc: 0.9878 - val_loss: 0.0224 - val_acc: 0.9937\n",
      "Epoch 2/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9945Epoch 00002: val_acc improved from 0.99375 to 0.99505, saving model to weights/weights-02-0.0156.hdf5\n",
      "347688/347688 [==============================] - 63s 182us/step - loss: 0.0201 - acc: 0.9945 - val_loss: 0.0156 - val_acc: 0.9951\n",
      "Epoch 3/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9958Epoch 00003: val_acc improved from 0.99505 to 0.99624, saving model to weights/weights-03-0.0135.hdf5\n",
      "347688/347688 [==============================] - 63s 182us/step - loss: 0.0149 - acc: 0.9958 - val_loss: 0.0135 - val_acc: 0.9962\n",
      "Epoch 4/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9963Epoch 00004: val_acc improved from 0.99624 to 0.99655, saving model to weights/weights-04-0.0113.hdf5\n",
      "347688/347688 [==============================] - 64s 183us/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.0113 - val_acc: 0.9966\n",
      "Epoch 5/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9969Epoch 00005: val_acc improved from 0.99655 to 0.99683, saving model to weights/weights-05-0.0105.hdf5\n",
      "347688/347688 [==============================] - 63s 182us/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0105 - val_acc: 0.9968\n",
      "Epoch 6/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9971Epoch 00006: val_acc improved from 0.99683 to 0.99702, saving model to weights/weights-06-0.0135.hdf5\n",
      "347688/347688 [==============================] - 63s 182us/step - loss: 0.0103 - acc: 0.9971 - val_loss: 0.0135 - val_acc: 0.9970\n",
      "Epoch 7/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9974Epoch 00007: val_acc improved from 0.99702 to 0.99721, saving model to weights/weights-07-0.0101.hdf5\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0101 - val_acc: 0.9972\n",
      "Epoch 8/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975Epoch 00008: val_acc improved from 0.99721 to 0.99756, saving model to weights/weights-08-0.0088.hdf5\n",
      "347688/347688 [==============================] - 64s 183us/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.0088 - val_acc: 0.9976\n",
      "Epoch 9/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9977Epoch 00009: val_acc improved from 0.99756 to 0.99763, saving model to weights/weights-09-0.0081.hdf5\n",
      "347688/347688 [==============================] - 63s 182us/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0081 - val_acc: 0.9976\n",
      "Epoch 10/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9976Epoch 00010: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0095 - val_acc: 0.9976\n",
      "Epoch 11/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9978Epoch 00011: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0099 - val_acc: 0.9974\n",
      "Epoch 12/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9979Epoch 00012: val_acc improved from 0.99763 to 0.99771, saving model to weights/weights-12-0.0083.hdf5\n",
      "347688/347688 [==============================] - 64s 183us/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0083 - val_acc: 0.9977\n",
      "Epoch 13/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9979Epoch 00013: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.0092 - val_acc: 0.9975\n",
      "Epoch 14/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9979Epoch 00014: val_acc improved from 0.99771 to 0.99782, saving model to weights/weights-14-0.0074.hdf5\n",
      "347688/347688 [==============================] - 64s 183us/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.0074 - val_acc: 0.9978\n",
      "Epoch 15/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9980Epoch 00015: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0117 - val_acc: 0.9973\n",
      "Epoch 16/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9981Epoch 00016: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0077 - val_acc: 0.9977\n",
      "Epoch 17/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9980Epoch 00017: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0094 - acc: 0.9980 - val_loss: 0.0136 - val_acc: 0.9954\n",
      "Epoch 18/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9981Epoch 00018: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0076 - val_acc: 0.9978\n",
      "Epoch 19/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9981Epoch 00019: val_acc improved from 0.99782 to 0.99797, saving model to weights/weights-19-0.0080.hdf5\n",
      "347688/347688 [==============================] - 64s 183us/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0080 - val_acc: 0.9980\n",
      "Epoch 20/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9982Epoch 00020: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0084 - val_acc: 0.9979\n",
      "Epoch 21/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9981Epoch 00021: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0086 - val_acc: 0.9980\n",
      "Epoch 22/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9973Epoch 00022: val_acc improved from 0.99797 to 0.99805, saving model to weights/weights-22-0.0073.hdf5\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0205 - acc: 0.9973 - val_loss: 0.0073 - val_acc: 0.9980\n",
      "Epoch 23/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9982Epoch 00023: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0084 - val_acc: 0.9979\n",
      "Epoch 24/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9977Epoch 00024: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0146 - acc: 0.9977 - val_loss: 0.0086 - val_acc: 0.9978\n",
      "Epoch 25/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9983Epoch 00025: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0072 - val_acc: 0.9980\n",
      "Epoch 26/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9979Epoch 00026: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0114 - acc: 0.9979 - val_loss: 0.0075 - val_acc: 0.9980\n",
      "Epoch 27/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9982Epoch 00027: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0086 - acc: 0.9982 - val_loss: 0.0099 - val_acc: 0.9978\n",
      "Epoch 28/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9982Epoch 00028: val_acc improved from 0.99805 to 0.99807, saving model to weights/weights-28-0.0073.hdf5\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0073 - acc: 0.9982 - val_loss: 0.0073 - val_acc: 0.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9983Epoch 00029: val_acc improved from 0.99807 to 0.99812, saving model to weights/weights-29-0.0068.hdf5\n",
      "347688/347688 [==============================] - 64s 183us/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 30/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9982Epoch 00030: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0090 - val_acc: 0.9981\n",
      "Epoch 31/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9967Epoch 00031: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0346 - acc: 0.9965 - val_loss: 6.1823 - val_acc: 0.6150\n",
      "Epoch 32/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 1.6405 - acc: 0.8855Epoch 00032: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 1.6397 - acc: 0.8856 - val_loss: 0.0242 - val_acc: 0.9967\n",
      "Epoch 33/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9969Epoch 00033: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0213 - acc: 0.9969 - val_loss: 0.0216 - val_acc: 0.9962\n",
      "Epoch 34/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9969Epoch 00034: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0220 - acc: 0.9969 - val_loss: 0.0262 - val_acc: 0.9971\n",
      "Epoch 35/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9970Epoch 00035: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0201 - acc: 0.9970 - val_loss: 0.0150 - val_acc: 0.9970\n",
      "Epoch 36/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9972Epoch 00036: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0166 - acc: 0.9972 - val_loss: 0.0245 - val_acc: 0.9950\n",
      "Epoch 37/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9974Epoch 00037: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0142 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9946\n",
      "Epoch 38/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9963Epoch 00038: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0192 - acc: 0.9963 - val_loss: 0.0149 - val_acc: 0.9974\n",
      "Epoch 39/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9961Epoch 00039: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0210 - acc: 0.9961 - val_loss: 0.0178 - val_acc: 0.9963\n",
      "Epoch 40/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9972Epoch 00040: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0144 - acc: 0.9972 - val_loss: 0.0159 - val_acc: 0.9974\n",
      "Epoch 41/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9967Epoch 00041: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0231 - acc: 0.9967 - val_loss: 0.2159 - val_acc: 0.9848\n",
      "Epoch 42/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9959Epoch 00042: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0241 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9958\n",
      "Epoch 43/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9904Epoch 00043: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0742 - acc: 0.9904 - val_loss: 0.0139 - val_acc: 0.9972\n",
      "Epoch 44/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9976Epoch 00044: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0108 - acc: 0.9976 - val_loss: 0.0092 - val_acc: 0.9979\n",
      "Epoch 45/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9976Epoch 00045: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0113 - acc: 0.9976 - val_loss: 0.0158 - val_acc: 0.9972\n",
      "Epoch 46/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9981Epoch 00046: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0087 - val_acc: 0.9980\n",
      "Epoch 47/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9970Epoch 00047: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0259 - acc: 0.9970 - val_loss: 0.0086 - val_acc: 0.9981\n",
      "Epoch 48/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9977Epoch 00048: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0168 - acc: 0.9977 - val_loss: 0.0080 - val_acc: 0.9980\n",
      "Epoch 49/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9980Epoch 00049: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0097 - acc: 0.9980 - val_loss: 0.0115 - val_acc: 0.9978\n",
      "Epoch 50/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9979Epoch 00050: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0110 - acc: 0.9979 - val_loss: 0.0095 - val_acc: 0.9979\n",
      "Epoch 51/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9974Epoch 00051: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0179 - acc: 0.9974 - val_loss: 0.0100 - val_acc: 0.9979\n",
      "Epoch 52/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9980Epoch 00052: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "Epoch 53/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9982Epoch 00053: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "Epoch 54/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9969Epoch 00054: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0214 - acc: 0.9969 - val_loss: 0.5998 - val_acc: 0.9610\n",
      "Epoch 55/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9951Epoch 00055: val_acc improved from 0.99812 to 0.99827, saving model to weights/weights-55-0.0115.hdf5\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0589 - acc: 0.9951 - val_loss: 0.0115 - val_acc: 0.9983\n",
      "Epoch 56/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9981Epoch 00056: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0094 - acc: 0.9981 - val_loss: 0.0090 - val_acc: 0.9979\n",
      "Epoch 57/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9982Epoch 00057: val_acc improved from 0.99827 to 0.99828, saving model to weights/weights-57-0.0089.hdf5\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0089 - val_acc: 0.9983\n",
      "Epoch 58/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9982Epoch 00058: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0089 - acc: 0.9982 - val_loss: 0.0091 - val_acc: 0.9982\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9981Epoch 00059: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0115 - acc: 0.9981 - val_loss: 0.0140 - val_acc: 0.9979\n",
      "Epoch 60/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9980Epoch 00060: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0137 - acc: 0.9980 - val_loss: 0.0117 - val_acc: 0.9981\n",
      "Epoch 61/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9976Epoch 00061: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0203 - acc: 0.9976 - val_loss: 0.0091 - val_acc: 0.9979\n",
      "Epoch 62/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9984Epoch 00062: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0072 - acc: 0.9984 - val_loss: 0.0080 - val_acc: 0.9982\n",
      "Epoch 63/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9982Epoch 00063: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0107 - acc: 0.9982 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 64/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9983Epoch 00064: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0093 - acc: 0.9983 - val_loss: 0.0128 - val_acc: 0.9983\n",
      "Epoch 65/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9979Epoch 00065: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0163 - acc: 0.9979 - val_loss: 0.0106 - val_acc: 0.9978\n",
      "Epoch 66/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9983Epoch 00066: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.0108 - val_acc: 0.9980\n",
      "Epoch 67/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 1.5498 - acc: 0.9027Epoch 00067: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 1.5517 - acc: 0.9026 - val_loss: 6.1844 - val_acc: 0.6148\n",
      "Epoch 68/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 1.4853 - acc: 0.9066Epoch 00068: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 1.4843 - acc: 0.9066 - val_loss: 0.0100 - val_acc: 0.9982\n",
      "Epoch 69/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9983Epoch 00069: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0096 - val_acc: 0.9979\n",
      "Epoch 70/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9982Epoch 00070: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0091 - acc: 0.9982 - val_loss: 0.0088 - val_acc: 0.9982\n",
      "Epoch 71/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9984Epoch 00071: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0079 - acc: 0.9984 - val_loss: 0.0088 - val_acc: 0.9982\n",
      "Epoch 72/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9984Epoch 00072: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0103 - acc: 0.9984 - val_loss: 0.0212 - val_acc: 0.9977\n",
      "Epoch 73/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9984Epoch 00073: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0116 - acc: 0.9984 - val_loss: 0.0153 - val_acc: 0.9981\n",
      "Epoch 74/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9977Epoch 00074: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0236 - acc: 0.9977 - val_loss: 0.0146 - val_acc: 0.9982\n",
      "Epoch 75/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9980Epoch 00075: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0124 - acc: 0.9980 - val_loss: 0.0105 - val_acc: 0.9980\n",
      "Epoch 76/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9984Epoch 00076: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0100 - acc: 0.9984 - val_loss: 0.0157 - val_acc: 0.9967\n",
      "Epoch 77/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9984Epoch 00077: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0106 - acc: 0.9984 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 78/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9982Epoch 00078: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0092 - acc: 0.9982 - val_loss: 0.0096 - val_acc: 0.9982\n",
      "Epoch 79/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9984Epoch 00079: val_acc improved from 0.99828 to 0.99841, saving model to weights/weights-79-0.0086.hdf5\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0079 - acc: 0.9984 - val_loss: 0.0086 - val_acc: 0.9984\n",
      "Epoch 80/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9984Epoch 00080: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0081 - acc: 0.9984 - val_loss: 0.0087 - val_acc: 0.9983\n",
      "Epoch 81/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9965Epoch 00081: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0381 - acc: 0.9965 - val_loss: 0.0094 - val_acc: 0.9981\n",
      "Epoch 82/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9975Epoch 00082: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0277 - acc: 0.9975 - val_loss: 0.0177 - val_acc: 0.9982\n",
      "Epoch 83/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9984Epoch 00083: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0098 - acc: 0.9984 - val_loss: 0.0098 - val_acc: 0.9984\n",
      "Epoch 84/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.9695 - acc: 0.9393Epoch 00084: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.9697 - acc: 0.9392 - val_loss: 1.9813 - val_acc: 0.8769\n",
      "Epoch 85/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 1.9939 - acc: 0.8762Epoch 00085: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 1.9937 - acc: 0.8762 - val_loss: 1.9816 - val_acc: 0.8770\n",
      "Epoch 86/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 1.9889 - acc: 0.8766Epoch 00086: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 1.9888 - acc: 0.8766 - val_loss: 1.9821 - val_acc: 0.8770\n",
      "Epoch 87/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 1.9886 - acc: 0.8766Epoch 00087: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 1.9888 - acc: 0.8766 - val_loss: 1.9815 - val_acc: 0.8771\n",
      "Epoch 88/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 1.0166 - acc: 0.9365Epoch 00088: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 1.0164 - acc: 0.9365 - val_loss: 0.0180 - val_acc: 0.9980\n",
      "Epoch 89/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9983Epoch 00089: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0140 - acc: 0.9983 - val_loss: 0.0162 - val_acc: 0.9982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9982Epoch 00090: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0110 - acc: 0.9982 - val_loss: 0.0126 - val_acc: 0.9974\n",
      "Epoch 91/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9983Epoch 00091: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0098 - acc: 0.9983 - val_loss: 0.0103 - val_acc: 0.9982\n",
      "Epoch 92/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9984Epoch 00092: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0098 - acc: 0.9984 - val_loss: 0.0124 - val_acc: 0.9981\n",
      "Epoch 93/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9964Epoch 00093: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0427 - acc: 0.9964 - val_loss: 0.0350 - val_acc: 0.9968\n",
      "Epoch 94/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9978Epoch 00094: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0206 - acc: 0.9978 - val_loss: 0.0188 - val_acc: 0.9979\n",
      "Epoch 95/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9964Epoch 00095: val_acc did not improve\n",
      "347688/347688 [==============================] - 66s 189us/step - loss: 0.0432 - acc: 0.9964 - val_loss: 0.0590 - val_acc: 0.9952\n",
      "Epoch 96/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9981Epoch 00096: val_acc did not improve\n",
      "347688/347688 [==============================] - 64s 185us/step - loss: 0.0141 - acc: 0.9981 - val_loss: 0.1910 - val_acc: 0.9878\n",
      "Epoch 97/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9979Epoch 00097: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0164 - acc: 0.9979 - val_loss: 0.0156 - val_acc: 0.9980\n",
      "Epoch 98/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9979Epoch 00098: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0157 - acc: 0.9979 - val_loss: 0.0185 - val_acc: 0.9976\n",
      "Epoch 99/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9970Epoch 00099: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 182us/step - loss: 0.0346 - acc: 0.9970 - val_loss: 0.0217 - val_acc: 0.9977\n",
      "Epoch 100/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9979Epoch 00100: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 182us/step - loss: 0.0193 - acc: 0.9979 - val_loss: 0.0236 - val_acc: 0.9973\n",
      "Epoch 101/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9965Epoch 00101: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0403 - acc: 0.9965 - val_loss: 0.1016 - val_acc: 0.9926\n",
      "Epoch 102/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9956Epoch 00102: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0557 - acc: 0.9956 - val_loss: 0.0480 - val_acc: 0.9961\n",
      "Epoch 103/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9949Epoch 00103: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0684 - acc: 0.9949 - val_loss: 0.0897 - val_acc: 0.9938\n",
      "Epoch 104/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9920Epoch 00104: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.1199 - acc: 0.9920 - val_loss: 0.1473 - val_acc: 0.9902\n",
      "Epoch 105/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9957Epoch 00105: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0587 - acc: 0.9957 - val_loss: 0.0500 - val_acc: 0.9959\n",
      "Epoch 106/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9953Epoch 00106: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0604 - acc: 0.9953 - val_loss: 0.1076 - val_acc: 0.9918\n",
      "Epoch 107/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9963Epoch 00107: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0454 - acc: 0.9963 - val_loss: 0.0469 - val_acc: 0.9961\n",
      "Epoch 108/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9962Epoch 00108: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0480 - acc: 0.9962 - val_loss: 0.0612 - val_acc: 0.9951\n",
      "Epoch 109/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9960Epoch 00109: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0506 - acc: 0.9960 - val_loss: 0.0506 - val_acc: 0.9960\n",
      "Epoch 110/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.3266 - acc: 0.9784Epoch 00110: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.3264 - acc: 0.9784 - val_loss: 0.1181 - val_acc: 0.9912\n",
      "Epoch 111/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9940Epoch 00111: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0428 - acc: 0.9940 - val_loss: 0.0377 - val_acc: 0.9940\n",
      "Epoch 112/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9929Epoch 00112: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0435 - acc: 0.9929 - val_loss: 0.0313 - val_acc: 0.9953\n",
      "Epoch 113/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9956Epoch 00113: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0326 - acc: 0.9956 - val_loss: 0.0402 - val_acc: 0.9948\n",
      "Epoch 114/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9929Epoch 00114: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0725 - acc: 0.9929 - val_loss: 0.0337 - val_acc: 0.9960\n",
      "Epoch 115/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9946Epoch 00115: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0362 - acc: 0.9946 - val_loss: 0.0669 - val_acc: 0.9868\n",
      "Epoch 116/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9931Epoch 00116: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0509 - acc: 0.9931 - val_loss: 0.0405 - val_acc: 0.9959\n",
      "Epoch 117/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9924Epoch 00117: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0438 - acc: 0.9924 - val_loss: 0.0406 - val_acc: 0.9930\n",
      "Epoch 118/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9937Epoch 00118: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0376 - acc: 0.9937 - val_loss: 0.0368 - val_acc: 0.9945\n",
      "Epoch 119/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9941Epoch 00119: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0362 - acc: 0.9941 - val_loss: 0.0309 - val_acc: 0.9926\n",
      "Epoch 120/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9952Epoch 00120: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0278 - acc: 0.9952 - val_loss: 0.0251 - val_acc: 0.9958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9961Epoch 00121: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0246 - acc: 0.9961 - val_loss: 0.0216 - val_acc: 0.9969\n",
      "Epoch 122/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9973Epoch 00122: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 182us/step - loss: 0.0205 - acc: 0.9973 - val_loss: 0.0343 - val_acc: 0.9965\n",
      "Epoch 123/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9906Epoch 00123: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.1277 - acc: 0.9906 - val_loss: 0.0658 - val_acc: 0.9947\n",
      "Epoch 124/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9947Epoch 00124: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0579 - acc: 0.9947 - val_loss: 0.0955 - val_acc: 0.9929\n",
      "Epoch 125/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.1657 - acc: 0.9889Epoch 00125: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.1657 - acc: 0.9889 - val_loss: 0.1698 - val_acc: 0.9885\n",
      "Epoch 126/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9931Epoch 00126: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0918 - acc: 0.9931 - val_loss: 0.0829 - val_acc: 0.9937\n",
      "Epoch 127/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9955Epoch 00127: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0557 - acc: 0.9955 - val_loss: 0.0531 - val_acc: 0.9957\n",
      "Epoch 128/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9956Epoch 00128: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0595 - acc: 0.9956 - val_loss: 0.1016 - val_acc: 0.9931\n",
      "Epoch 129/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9913Epoch 00129: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.1371 - acc: 0.9913 - val_loss: 0.1080 - val_acc: 0.9931\n",
      "Epoch 130/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9939Epoch 00130: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0954 - acc: 0.9939 - val_loss: 0.1076 - val_acc: 0.9931\n",
      "Epoch 131/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9946Epoch 00131: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0626 - acc: 0.9946 - val_loss: 0.0394 - val_acc: 0.9951\n",
      "Epoch 132/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9951Epoch 00132: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0490 - acc: 0.9950 - val_loss: 0.5466 - val_acc: 0.9658\n",
      "Epoch 133/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.9695Epoch 00133: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.4867 - acc: 0.9695 - val_loss: 0.1588 - val_acc: 0.9891\n",
      "Epoch 134/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9920Epoch 00134: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.1200 - acc: 0.9920 - val_loss: 0.1382 - val_acc: 0.9908\n",
      "Epoch 135/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9909Epoch 00135: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.1371 - acc: 0.9909 - val_loss: 0.1568 - val_acc: 0.9897\n",
      "Epoch 136/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9910Epoch 00136: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.1338 - acc: 0.9910 - val_loss: 0.1001 - val_acc: 0.9925\n",
      "Epoch 137/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9912Epoch 00137: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.1262 - acc: 0.9912 - val_loss: 0.1549 - val_acc: 0.9897\n",
      "Epoch 138/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.1909 - acc: 0.9695Epoch 00138: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.1908 - acc: 0.9695 - val_loss: 0.1325 - val_acc: 0.9808\n",
      "Epoch 139/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9856Epoch 00139: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.1063 - acc: 0.9856 - val_loss: 0.0704 - val_acc: 0.9935\n",
      "Epoch 140/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.1661 - acc: 0.9884Epoch 00140: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.1660 - acc: 0.9884 - val_loss: 0.3401 - val_acc: 0.9788\n",
      "Epoch 141/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.2906 - acc: 0.9819Epoch 00141: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.2905 - acc: 0.9819 - val_loss: 0.1415 - val_acc: 0.9910\n",
      "Epoch 142/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9954Epoch 00142: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0649 - acc: 0.9954 - val_loss: 0.0721 - val_acc: 0.9952\n",
      "Epoch 143/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9958Epoch 00143: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0634 - acc: 0.9958 - val_loss: 0.0722 - val_acc: 0.9952\n",
      "Epoch 144/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9927Epoch 00144: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.1144 - acc: 0.9927 - val_loss: 0.2109 - val_acc: 0.9868\n",
      "Epoch 145/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9938Epoch 00145: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0948 - acc: 0.9938 - val_loss: 0.0751 - val_acc: 0.9949\n",
      "Epoch 146/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9956Epoch 00146: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0660 - acc: 0.9956 - val_loss: 0.0751 - val_acc: 0.9949\n",
      "Epoch 147/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9956Epoch 00147: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0660 - acc: 0.9956 - val_loss: 0.0751 - val_acc: 0.9949\n",
      "Epoch 148/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9956Epoch 00148: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0660 - acc: 0.9956 - val_loss: 0.0751 - val_acc: 0.9949\n",
      "Epoch 149/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9956Epoch 00149: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0660 - acc: 0.9956 - val_loss: 0.0751 - val_acc: 0.9949\n",
      "Epoch 150/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9942Epoch 00150: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0654 - acc: 0.9942 - val_loss: 0.0687 - val_acc: 0.9922\n",
      "Epoch 151/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9925Epoch 00151: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0686 - val_acc: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9925Epoch 00152: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0686 - val_acc: 0.9922\n",
      "Epoch 153/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00153: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0686 - val_acc: 0.9922\n",
      "Epoch 154/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00154: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 155/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00155: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 156/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9926Epoch 00156: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 157/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00157: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 158/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00158: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 159/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00159: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 160/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00160: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 161/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00161: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 162/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00162: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 163/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00163: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 164/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00164: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9926Epoch 00165: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 166/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00166: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 167/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00167: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 168/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00168: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 169/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00169: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 170/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00170: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 171/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00171: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 172/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00172: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 173/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00173: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 174/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00174: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 175/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00175: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 176/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00176: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 177/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9926Epoch 00177: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 178/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00178: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 179/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9926Epoch 00179: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 180/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00180: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 181/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9926Epoch 00181: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 182/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00182: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 178us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00183: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 184/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00184: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 185/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00185: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 186/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00186: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 187/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00187: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 181us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 188/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00188: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 189/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00189: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 190/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00190: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 191/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00191: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 192/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00192: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 193/200\n",
      "347520/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00193: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 194/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00194: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 195/200\n",
      "347456/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00195: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 196/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00196: val_acc did not improve\n",
      "347688/347688 [==============================] - 62s 179us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 197/200\n",
      "347584/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00197: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 198/200\n",
      "347392/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00198: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 199/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9925Epoch 00199: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n",
      "Epoch 200/200\n",
      "347648/347688 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9926Epoch 00200: val_acc did not improve\n",
      "347688/347688 [==============================] - 63s 180us/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0685 - val_acc: 0.9922\n"
     ]
    }
   ],
   "source": [
    "neuralnetQuestionType.fit(questions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VQA annotations and questions into memory...\n",
      "0:00:02.240788\n",
      "creating index...\n",
      "index created!\n",
      "loading VQA annotations and questions into memory...\n",
      "0:00:03.532234\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5bd33a247b86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/dictionary_all_types.pkl'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Use same dictionary as in training\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image features\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Question features\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dictionary size\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdic_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Load validation set and evaluate prediction on it\n",
    "pt= PrepareData(path_images='data_vqa_feat', # Path to image features \n",
    "                        subset='val2014', # Desired subset: either train2014 or val2014\n",
    "                        taskType=taskType, # 'OpenEnded', 'MultipleChoice', 'all'\n",
    "                        cut_data=data_amount, # Percentage of data to use, 1 = All values, above 1 = 10 samples for debugging\n",
    "                        output_path='data', # Path where we want to output temporary data\n",
    "                        pad_length=32)\n",
    "pt.loadDictionary('data/dictionary_all_types.pkl') # Use same dictionary as in training\n",
    "_, questions, _, annotations = pt.load_data()\n",
    "#print(\"Image features\", image_features.shape)\n",
    "print(\"Question features\", questions.shape)\n",
    "print(\"Dictionary size\", pt.dic_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243024,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check prediction accuracy of answer-type classifier\n",
    "y = np.array([2 if ann['answer_type'] == 'number' else 1 if ann['answer_type'] == 'yes/no' else 0 for ann in annotations])\n",
    "\n",
    "# Predict\n",
    "#pred = classifier.predict(questions)\n",
    "pred = neuralnetQuestionType.predict(questions, 'weights/weights-18-0.0089.hdf5')\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer type classification accuracy: 0.990206728554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# TODO: can probably still improve this accuracy\n",
    "print('Answer type classification accuracy:', accuracy_score(pred, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92090, 1024)\n",
      "(92090, 32)\n",
      "(92090,)\n"
     ]
    }
   ],
   "source": [
    "# Filter questions accordingly to their predicted type\n",
    "question_type_idx = 2 if question_type == 'number' else 1 if question_type == 'yes/no' else 0\n",
    "image_features = image_features[pred == question_type_idx, :]\n",
    "questions = questions[pred == question_type_idx, :]\n",
    "original_questions = np.array(pt._original_questions)[pred == question_type_idx]\n",
    "print(image_features.shape)\n",
    "print(questions.shape)\n",
    "print(original_questions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VQA annotations and questions into memory...\n",
      "0:00:02.359158\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "computing accuracy\n",
      "Finshed Percent: [####################] 99% Done computing accuracy\n",
      "\n",
      "\n",
      "Overall Accuracy is: 74.84\n",
      "\n",
      "Per Question Type Accuracy is the following:\n",
      "is the : 72.66\n",
      "is this an : 75.10\n",
      "are there : 80.00\n",
      "is it : 77.09\n",
      "is this : 74.65\n",
      "is there a : 85.36\n",
      "is the person : 75.09\n",
      "is this a : 77.13\n",
      "do : 69.75\n",
      "are the : 72.02\n",
      "are : 72.90\n",
      "does this : 75.08\n",
      "has : 76.46\n",
      "is the man : 75.31\n",
      "are they : 74.64\n",
      "is : 76.32\n",
      "is this person : 71.16\n",
      "are these : 73.15\n",
      "is there : 80.02\n",
      "do you : 75.62\n",
      "none of the above : 68.61\n",
      "does the : 73.37\n",
      "are there any : 72.74\n",
      "is he : 75.50\n",
      "is the woman : 73.87\n",
      "was : 73.36\n",
      "could : 85.54\n",
      "can you : 71.99\n",
      "is that a : 75.54\n",
      "how : 3.60\n",
      "what : 0.00\n",
      "how many : 0.00\n",
      "\n",
      "\n",
      "Per Answer Type Accuracy is the following:\n",
      "yes/no : 76.03\n",
      "other : 8.04\n",
      "number : 7.04\n",
      "\n",
      "\n",
      "loading VQA annotations and questions into memory...\n",
      "0:00:02.705804\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "computing accuracy\n",
      "Finshed Percent: [####################] 99% Done computing accuracy\n",
      "\n",
      "\n",
      "Overall Accuracy is: 74.84\n",
      "\n",
      "Per Question Type Accuracy is the following:\n",
      "is the : 72.66\n",
      "is this an : 75.10\n",
      "are there : 80.00\n",
      "is it : 77.09\n",
      "is this : 74.65\n",
      "is there a : 85.36\n",
      "is the person : 75.09\n",
      "is this a : 77.13\n",
      "do : 69.75\n",
      "are the : 72.02\n",
      "are : 72.90\n",
      "does this : 75.08\n",
      "has : 76.46\n",
      "is the man : 75.31\n",
      "are they : 74.64\n",
      "is : 76.32\n",
      "is this person : 71.16\n",
      "are these : 73.15\n",
      "is there : 80.02\n",
      "do you : 75.62\n",
      "none of the above : 68.61\n",
      "does the : 73.37\n",
      "are there any : 72.74\n",
      "is he : 75.50\n",
      "is the woman : 73.87\n",
      "was : 73.36\n",
      "could : 85.54\n",
      "can you : 71.99\n",
      "is that a : 75.54\n",
      "how : 3.60\n",
      "what : 0.00\n",
      "how many : 0.00\n",
      "\n",
      "\n",
      "Per Answer Type Accuracy is the following:\n",
      "yes/no : 76.03\n",
      "other : 8.04\n",
      "number : 7.04\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from EvaluateModel import ProduceResult\n",
    "model_evaluator = ProduceResult(p._int_to_answer, p._answer_to_int, dataSubType='val2014')\n",
    "answers = model_evaluator.produce_results(pred, original_questions)\n",
    "model_evaluator.evaluate(taskType=taskType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
